from __future__ import print_function
import six
import sys
import os
from optparse import OptionParser
from keras.models import load_model, Model
from argparse import ArgumentParser
from keras import backend as K
import numpy as np

# fix random seed for reproducibility
seed = 42
np.random.seed(seed)
import h5py
import matplotlib

matplotlib.use("agg")
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.metrics import confusion_matrix
import itertools
from constraints import ZeroSomeWeights
from keras.utils.generic_utils import get_custom_objects

get_custom_objects().update({"ZeroSomeWeights": ZeroSomeWeights})
import yaml
from train import parse_config, get_features
from quantized_layers import Clip, BinaryDense, TernaryDense, QuantizedDense
from models import binary_tanh, ternary_tanh, quantized_relu

# To turn off GPU
# os.environ['CUDA_VISIBLE_DEVICES'] = ''

# confusion matrix code from Maurizio
# /eos/user/m/mpierini/DeepLearning/ML4FPGA/jupyter/HbbTagger_Conv1D.ipynb
def plot_confusion_matrix(
    cm, classes, normalize=False, title="Confusion matrix", cmap=plt.cm.Blues
):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]

    plt.imshow(cm, interpolation="nearest", cmap=cmap)
    # plt.title(title)
    cbar = plt.colorbar()
    plt.clim(0, 1)
    cbar.set_label(title)
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = ".2f" if normalize else "d"
    thresh = cm.max() / 2.0
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(
            j,
            i,
            format(cm[i, j], fmt),
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black",
        )

    # plt.tight_layout()
    plt.ylabel("True label")
    plt.xlabel("Predicted label")


def makeRoc(features_val, labels, labels_val, model, outputDir):

    print("in makeRoc()")
    if "j_index" in labels:
        labels.remove("j_index")

    predict_test = model.predict(features_val)

    df = pd.DataFrame()

    fpr = {}
    tpr = {}
    auc1 = {}

    plt.figure()
    for i, label in enumerate(labels):
        df[label] = labels_val[:, i]
        df[label + "_pred"] = predict_test[:, i]

        fpr[label], tpr[label], threshold = roc_curve(df[label], df[label + "_pred"])

        auc1[label] = auc(fpr[label], tpr[label])

        plt.plot(
            tpr[label],
            fpr[label],
            label="%s tagger, AUC = %.1f%%"
            % (label.replace("j_", ""), auc1[label] * 100.0),
        )
    plt.semilogy()
    plt.xlabel("Signal Efficiency")
    plt.ylabel("Background Efficiency")
    plt.ylim(0.001, 1)
    plt.grid(True)
    plt.legend(loc="upper left")
    plt.figtext(
        0.25,
        0.90,
        "hls4ml",
        fontweight="bold",
        wrap=True,
        horizontalalignment="right",
        fontsize=14,
    )
    # plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14)
    plt.savefig("%s/ROC.pdf" % (options.outputDir))
    return predict_test


def _byteify(data, ignore_dicts=False):
    # if this is a unicode string, return its string representation
    if isinstance(data, six.text_type):
        return data.encode("utf-8")
    # if this is a list of values, return list of byteified values
    if isinstance(data, list):
        return [_byteify(item, ignore_dicts=True) for item in data]
    # if this is a dictionary, return dictionary of byteified keys and values
    # but only if we haven't already byteified it
    if isinstance(data, dict) and not ignore_dicts:
        return {
            _byteify(key, ignore_dicts=True): _byteify(value, ignore_dicts=True)
            for key, value in data.items()
        }
    # if it's anything else, return it in its original form
    return data


if __name__ == "__main__":
    parser = OptionParser()
    parser.add_option(
        "-m",
        "--model",
        action="store",
        type="string",
        dest="inputModel",
        default="train_simple/KERAS_check_best_model.h5",
        help="input model",
    )
    parser.add_option(
        "-i",
        "--input",
        action="store",
        type="string",
        dest="inputFile",
        default="../data/processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_truth.z",
        help="input file",
    )
    parser.add_option(
        "-t",
        "--tree",
        action="store",
        type="string",
        dest="tree",
        default="t_allpar_new",
        help="tree name",
    )
    parser.add_option(
        "-o",
        "--output",
        action="store",
        type="string",
        dest="outputDir",
        default="eval_simple/",
        help="output directory",
    )
    parser.add_option(
        "-c",
        "--config",
        action="store",
        type="string",
        dest="config",
        default="train_config_threelayer.yml",
        help="configuration file",
    )
    (options, args) = parser.parse_args()

    yamlConfig = parse_config(options.config)

    if os.path.isdir(options.outputDir):
        # raise Exception('output directory must not exist yet')
        raw_input("Warning: output directory exists. Press Enter to continue...")
    else:
        os.mkdir(options.outputDir)

    X_train_val, X_test, y_train_val, y_test, labels = get_features(options, yamlConfig)

    model = load_model(
        options.inputModel,
        custom_objects={
            "ZeroSomeWeights": ZeroSomeWeights,
            "BinaryDense": BinaryDense,
            "TernaryDense": TernaryDense,
            "QuantizedDense": QuantizedDense,
            "binary_tanh": binary_tanh,
            "ternary_tanh": ternary_tanh,
            "quantized_relu": quantized_relu,
            "Clip": Clip,
        },
    )

    y_predict = makeRoc(X_test, labels, y_test, model, options.outputDir)
    y_test_proba = y_test.argmax(axis=1)
    y_predict_proba = y_predict.argmax(axis=1)
    # Compute non-normalized confusion matrix
    cnf_matrix = confusion_matrix(y_test_proba, y_predict_proba)
    np.set_printoptions(precision=2)
    # Plot non-normalized confusion matrix
    plt.figure()
    plot_confusion_matrix(
        cnf_matrix,
        classes=[l.replace("j_", "") for l in labels],
        title="Confusion matrix",
    )
    plt.figtext(
        0.28,
        0.90,
        "hls4ml",
        fontweight="bold",
        wrap=True,
        horizontalalignment="right",
        fontsize=14,
    )
    # plt.figtext(0.38, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14)
    plt.savefig(options.outputDir + "/confusion_matrix.pdf")
    # Plot normalized confusion matrix
    plt.figure()
    plot_confusion_matrix(
        cnf_matrix,
        classes=[l.replace("j_", "") for l in labels],
        normalize=True,
        title="Normalized confusion matrix",
    )

    plt.figtext(
        0.28,
        0.90,
        "hls4ml",
        fontweight="bold",
        wrap=True,
        horizontalalignment="right",
        fontsize=14,
    )
    # plt.figtext(0.38, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14)
    plt.savefig(options.outputDir + "/confusion_matrix_norm.pdf")

    import json

    if os.path.isfile("%s/full_info.log" % os.path.dirname(options.inputModel)):
        f = open("%s/full_info.log" % os.path.dirname(options.inputModel))
        myListOfDicts = json.load(f, object_hook=_byteify)
        myDictOfLists = {}
        for key, val in myListOfDicts[0].items():
            myDictOfLists[key] = []
        for i, myDict in enumerate(myListOfDicts):
            for key, val in myDict.items():
                myDictOfLists[key].append(myDict[key])

        plt.figure()
        val_loss = np.asarray(myDictOfLists[b"val_loss"])
        loss = np.asarray(myDictOfLists[b"loss"])
        plt.plot(val_loss, label="validation")
        plt.plot(loss, label="train")
        plt.legend()
        plt.xlabel("epoch")
        plt.ylabel("loss")
        plt.savefig(options.outputDir + "/loss.pdf")

        plt.figure()
        val_acc = np.asarray(myDictOfLists[b"val_acc"])
        acc = np.asarray(myDictOfLists[b"acc"])
        plt.plot(val_acc, label="validation")
        plt.plot(acc, label="train")
        plt.legend()
        plt.xlabel("epoch")
        plt.ylabel("accuracy")
        plt.savefig(options.outputDir + "/acc.pdf")
